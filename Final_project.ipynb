{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib notebook\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import flatten\n",
    "from nltk import FreqDist\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.tsv', sep='\\t') #importing the test frame\n",
    "train_df = pd.read_csv('train.tsv', sep = '\\t') #importing the train frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10) #looking at the first 10 rows of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info() #glancing throguh the info about the fram like the columns, their data types etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sentiment'].value_counts() #now as we have to predict the sentiment value, giving a good look at the count of each of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets look at the distribution of the sentiment over the train data\n",
    "plt.figure(figsize = [9,6])\n",
    "sns.countplot(x=\"Sentiment\", data=train_df)\n",
    "plt.title('Sentiment distribution')\n",
    "plt.ylabel('Total')\n",
    "plt.xlabel('Sentiment Number')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>8545</td>\n",
       "      <td>pleasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>8545</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine\n",
       "5    156066        8545                        intermittently pleasing but\n",
       "6    156067        8545                            intermittently pleasing\n",
       "7    156068        8545                                     intermittently\n",
       "8    156069        8545                                           pleasing\n",
       "9    156070        8545                                                but"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10) #repeating the above proess with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66292 entries, 0 to 66291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PhraseId    66292 non-null  int64 \n",
      " 1   SentenceId  66292 non-null  int64 \n",
      " 2   Phrase      66292 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') #defining the stopwords variable \n",
    "newstopwords = [word for word in stopwords if word not in ['not', 'no', 'can','don', 't','n']] #adding a few more that werent there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below created function is used to pre process the data especially focusing on the phrase column of the frame\n",
    "def sentence_cleaning(df):\n",
    "    sentence = []\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \",sent.lower())\n",
    "        word = word_tokenize(text.lower())\n",
    "        new_words = [ ele for ele in word if ele.lower() not in newstopwords ]\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemm_word = [lemmatizer.lemmatize(i) for i in new_words]\n",
    "        sentence.append(lemm_word)\n",
    "    return (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [00:29<00:00, 5309.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sentence = sentence_cleaning(train_df) #creating a different list by running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [00:25<00:00, 6062.52it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df['Phrase'] = sentence_cleaning(train_df) #now just also applying it on the column inside the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy = train_df #copying the train_df frame into another frame so that we dont mess up with the orignal frame\n",
    "train_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#top 200 most repeated words in the list\n",
    "flattened_list = flatten(train_sentence)\n",
    "def repeated_topwords(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = [w for (w, c) in wordlist.most_common(200)] \n",
    "    return word_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'movie', 't', 'n', 'one', 'not', 'like', 'character', 'story', 'time', 'rrb', 'make', 'good', 'lrb', 'life', 'comedy', 'no', 'much', 'way', 'can', 'work', 'even', 'little', 'funny', 'well', 'performance', 'director', 'love', 'year', 'feel', 'new', 'bad', 'u', 'enough', 'get', 'action', 'thing', 'made', 'old', 'audience', 'two', 'something', 'minute', 'would', 'best', 'look', 'never', 'many', 'people', 'come', 'see', 'self', 'plot', 'drama', 'world', 'take', 'first', 'may', 'could', 'better', 'long', 'go', 'big', 'sense', 'really', 'man', 'give', 'moment', 'actor', 'without', 'real', 'great', 'screen', 'every', 'humor', 'end', 'ever', 'family', 'scene', 'another', 'woman', 'american', 'heart', 'picture', 'cast', 'hollywood', 'human', 'still', 'hour', 'fun', 'le', 'nothing', 'hard', 'kid', 'kind', 'script', 'often', 'might', 'show', 'far', 'find', 'star', 'lot', 'war', 'acting', 'laugh', 'also', 'seen', 'thriller', 'back', 'interesting', 'original', 'day', 'rather', 'idea', 'watch', 'young', 'right', 'point', 'keep', 'almost', 'full', 'emotional', 'tale', 'entertaining', 'material', 'subject', 'cinema', 'want', 'documentary', 'filmmaker', 'dialogue', 'music', 'flick', 'style', 'place', 'need', 'know', 'piece', 'quite', 'romantic', 'half', 'yet', 'art', 'watching', 'bit', 'high', 'making', 'going', 'turn', 'fan', 'video', 'think', 'special', 'set', 'comic', 'play', 'worth', 'seems', 'girl', 'dark', 'child', 'ca', 'last', 'though', 'experience', 'feature', 'history', 'care', 'age', 'writer', 'seem', 'three', 'anything', 'part', 'compelling', 'say', 'least', 'eye', 'theater', 'viewer', 'lack', 'visual', 'around', 'ultimately', 'genre', 'together', 'effect', 'direction', 'culture', 'sometimes', 'entertainment', 'matter', 'face', 'power', 'sweet', 'true', 'offer', 'familiar', 'low']\n"
     ]
    }
   ],
   "source": [
    "#applying the feature and printing it\n",
    "features = repeated_topwords(flattened_list)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating unigram\n",
    "def unigram_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(film)': True, 'contains(movie)': True, 'contains(t)': True, 'contains(n)': True, 'contains(one)': True, 'contains(not)': True, 'contains(like)': True, 'contains(character)': True, 'contains(story)': True, 'contains(time)': True, 'contains(rrb)': True, 'contains(make)': True, 'contains(good)': True, 'contains(lrb)': True, 'contains(life)': True, 'contains(comedy)': True, 'contains(no)': True, 'contains(much)': True, 'contains(way)': True, 'contains(can)': True, 'contains(work)': True, 'contains(even)': True, 'contains(little)': True, 'contains(funny)': True, 'contains(well)': True, 'contains(performance)': True, 'contains(director)': True, 'contains(love)': True, 'contains(year)': True, 'contains(feel)': True, 'contains(new)': True, 'contains(bad)': True, 'contains(u)': True, 'contains(enough)': True, 'contains(get)': True, 'contains(action)': True, 'contains(thing)': True, 'contains(made)': True, 'contains(old)': True, 'contains(audience)': True, 'contains(two)': True, 'contains(something)': True, 'contains(minute)': True, 'contains(would)': True, 'contains(best)': True, 'contains(look)': True, 'contains(never)': True, 'contains(many)': True, 'contains(people)': True, 'contains(come)': True, 'contains(see)': True, 'contains(self)': True, 'contains(plot)': True, 'contains(drama)': True, 'contains(world)': True, 'contains(take)': True, 'contains(first)': True, 'contains(may)': True, 'contains(could)': True, 'contains(better)': True, 'contains(long)': True, 'contains(go)': True, 'contains(big)': True, 'contains(sense)': True, 'contains(really)': True, 'contains(man)': True, 'contains(give)': True, 'contains(moment)': True, 'contains(actor)': True, 'contains(without)': True, 'contains(real)': True, 'contains(great)': True, 'contains(screen)': True, 'contains(every)': True, 'contains(humor)': True, 'contains(end)': True, 'contains(ever)': True, 'contains(family)': True, 'contains(scene)': True, 'contains(another)': True, 'contains(woman)': True, 'contains(american)': True, 'contains(heart)': True, 'contains(picture)': True, 'contains(cast)': True, 'contains(hollywood)': True, 'contains(human)': True, 'contains(still)': True, 'contains(hour)': True, 'contains(fun)': True, 'contains(le)': True, 'contains(nothing)': True, 'contains(hard)': True, 'contains(kid)': True, 'contains(kind)': True, 'contains(script)': True, 'contains(often)': True, 'contains(might)': True, 'contains(show)': True, 'contains(far)': True, 'contains(find)': True, 'contains(star)': True, 'contains(lot)': True, 'contains(war)': True, 'contains(acting)': True, 'contains(laugh)': True, 'contains(also)': True, 'contains(seen)': True, 'contains(thriller)': True, 'contains(back)': True, 'contains(interesting)': True, 'contains(original)': True, 'contains(day)': True, 'contains(rather)': True, 'contains(idea)': True, 'contains(watch)': True, 'contains(young)': True, 'contains(right)': True, 'contains(point)': True, 'contains(keep)': True, 'contains(almost)': True, 'contains(full)': True, 'contains(emotional)': True, 'contains(tale)': True, 'contains(entertaining)': True, 'contains(material)': True, 'contains(subject)': True, 'contains(cinema)': True, 'contains(want)': True, 'contains(documentary)': True, 'contains(filmmaker)': True, 'contains(dialogue)': True, 'contains(music)': True, 'contains(flick)': True, 'contains(style)': True, 'contains(place)': True, 'contains(need)': True, 'contains(know)': True, 'contains(piece)': True, 'contains(quite)': True, 'contains(romantic)': True, 'contains(half)': True, 'contains(yet)': True, 'contains(art)': True, 'contains(watching)': True, 'contains(bit)': True, 'contains(high)': True, 'contains(making)': True, 'contains(going)': True, 'contains(turn)': True, 'contains(fan)': True, 'contains(video)': True, 'contains(think)': True, 'contains(special)': True, 'contains(set)': True, 'contains(comic)': True, 'contains(play)': True, 'contains(worth)': True, 'contains(seems)': True, 'contains(girl)': True, 'contains(dark)': True, 'contains(child)': True, 'contains(ca)': True, 'contains(last)': True, 'contains(though)': True, 'contains(experience)': True, 'contains(feature)': True, 'contains(history)': True, 'contains(care)': True, 'contains(age)': True, 'contains(writer)': True, 'contains(seem)': True, 'contains(three)': True, 'contains(anything)': True, 'contains(part)': True, 'contains(compelling)': True, 'contains(say)': True, 'contains(least)': True, 'contains(eye)': True, 'contains(theater)': True, 'contains(viewer)': True, 'contains(lack)': True, 'contains(visual)': True, 'contains(around)': True, 'contains(ultimately)': True, 'contains(genre)': True, 'contains(together)': True, 'contains(effect)': True, 'contains(direction)': True, 'contains(culture)': True, 'contains(sometimes)': True, 'contains(entertainment)': True, 'contains(matter)': True, 'contains(face)': True, 'contains(power)': True, 'contains(sweet)': True, 'contains(true)': True, 'contains(offer)': True, 'contains(familiar)': True, 'contains(low)': True}\n"
     ]
    }
   ],
   "source": [
    "#printing the unigram\n",
    "unigrams = unigram_features(flattened_list,features)\n",
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part of speech classifcation\n",
    "def POS_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    tagged_words = nltk.pos_tag(document)\n",
    "    features = {}\n",
    "    numNoun = 0\n",
    "    numVerb = 0\n",
    "    numAdj = 0\n",
    "    numAdverb = 0\n",
    "    for (word, tag) in tagged_words:\n",
    "        if tag.startswith('N'): numNoun += 1\n",
    "        if tag.startswith('V'): numVerb += 1\n",
    "        if tag.startswith('J'): numAdj += 1\n",
    "        if tag.startswith('R'): numAdverb += 1\n",
    "    features['nouns'] = numNoun\n",
    "    features['verbs'] = numVerb\n",
    "    features['adjectives'] = numAdj\n",
    "    features['adverbs'] = numAdverb\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nouns': 297190, 'verbs': 103255, 'adjectives': 154896, 'adverbs': 54015}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running the above created function and printing the output\n",
    "POS = POS_features(flattened_list,features)\n",
    "POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for the classification task we are just taking only 2 columns fro the main frame\n",
    "classdataframe = train_df_copy[['Phrase','Sentiment']]\n",
    "classdataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[series]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[series]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>[hearst]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>[forced, avuncular, chortle]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>[avuncular, chortle]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>[avuncular]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>[chortle]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrase  Sentiment\n",
       "0       [series, escapade, demonstrating, adage, good,...          1\n",
       "1       [series, escapade, demonstrating, adage, good,...          2\n",
       "2                                                [series]          2\n",
       "3                                                      []          2\n",
       "4                                                [series]          2\n",
       "...                                                   ...        ...\n",
       "156055                                           [hearst]          2\n",
       "156056                       [forced, avuncular, chortle]          1\n",
       "156057                               [avuncular, chortle]          3\n",
       "156058                                        [avuncular]          2\n",
       "156059                                          [chortle]          2\n",
       "\n",
       "[156060 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what this loop does is that it removes all of the square brackets and commas from each of the phrase line\n",
    "for i in tqdm(range(len(classdataframe))):\n",
    "    classdataframe['Phrase'][i] = (\" \").join(train_df_copy['Phrase'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    s e r i e s   e s c a p a d e   d e m o n s t ...\n",
       "1       series escapade demonstrating adage good goose\n",
       "2                                               series\n",
       "3                                                     \n",
       "4                                               series\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are justing trying to seperate the x and the y variable and giving them better names\n",
    "phrase = classdataframe['Phrase']\n",
    "sentiment = classdataframe['Sentiment']\n",
    "phrase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation split, not using test here because we have a different dataframe for test\n",
    "X_train,X_val,y_train,y_val = train_test_split(\\\n",
    "    phrase,sentiment,test_size = 0.3, random_state = 60,shuffle=True, stratify=sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Train Accuracy Score : 63.0% \n",
      "Naive Bayes Test Accuracy Score  : 58.0% \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.63      0.08       137\n",
      "           1       0.25      0.52      0.34      4000\n",
      "           2       0.89      0.60      0.72     35365\n",
      "           3       0.38      0.52      0.44      7114\n",
      "           4       0.04      0.61      0.08       202\n",
      "\n",
      "    accuracy                           0.58     46818\n",
      "   macro avg       0.32      0.58      0.33     46818\n",
      "weighted avg       0.76      0.58      0.64     46818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_text = vectorizer.fit_transform(X_train)\n",
    "#--Training the classifier with  Naive Bayes--\n",
    "nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train,y_train)\n",
    "test_predict = nb.predict(X_val)\n",
    "train_accuracy = round(nb.score(X_train,y_train)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, y_val)*100)\n",
    "print(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"Naive Bayes Test Accuracy Score  : {}% \".format(test_accuracy ))\n",
    "print()\n",
    "print(classification_report(test_predict, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy Score : 57.0% \n",
      "SVM Test Accuracy Score  : 56.0% \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.53      0.13       293\n",
      "           1       0.09      0.49      0.15      1486\n",
      "           2       0.96      0.56      0.71     40700\n",
      "           3       0.20      0.52      0.29      3773\n",
      "           4       0.11      0.56      0.19       566\n",
      "\n",
      "    accuracy                           0.56     46818\n",
      "   macro avg       0.29      0.53      0.29     46818\n",
      "weighted avg       0.86      0.56      0.65     46818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier()),\n",
    "               ])\n",
    "#--Training the classifier with  SVM--\n",
    "sgd.fit(X_train, y_train)\n",
    "test_predict = sgd.predict(X_val)\n",
    "train_accuracy = round(sgd.score(X_train,y_train)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, y_val)*100)\n",
    "print(\"SVM Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"SVM Test Accuracy Score  : {}% \".format(test_accuracy ))\n",
    "print()\n",
    "print(classification_report(test_predict, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy Score : 88.0% \n",
      "Decision Tree Test Accuracy Score  : 61.0% \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.40      0.41      2224\n",
      "           1       0.49      0.48      0.49      8319\n",
      "           2       0.75      0.72      0.73     25138\n",
      "           3       0.48      0.53      0.50      9054\n",
      "           4       0.36      0.47      0.41      2083\n",
      "\n",
      "    accuracy                           0.61     46818\n",
      "   macro avg       0.50      0.52      0.51     46818\n",
      "weighted avg       0.62      0.61      0.62     46818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('dt', DecisionTreeClassifier()),\n",
    "               ])\n",
    "#--Training the classifier with  Decision tree--\n",
    "dt.fit(X_train, y_train)\n",
    "test_predict = dt.predict(X_val)\n",
    "train_accuracy = round(dt.score(X_train,y_train)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, y_val)*100)\n",
    "print(\"Decision Tree Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"Decision Tree Test Accuracy Score  : {}% \".format(test_accuracy ))\n",
    "print()\n",
    "print(classification_report(test_predict, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66292/66292 [00:10<00:00, 6481.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the test dataframe\n",
    "test_df['Phrase'] = sentence_cleaning(test_df)\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    test_df['Phrase'][i] = (\" \").join(train_df_copy['Phrase'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66292 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|██████████| 66292/66292 [03:34<00:00, 309.28it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the decision tree predict on it, because we have the highest predicting accuracy\n",
    "test_id = test_df['PhraseId']\n",
    "test_text = test_df['Phrase']\n",
    "y_prdict = dt.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>156071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>156073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>156074</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>156075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>156078</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>156079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  Sentiment\n",
       "0     156061          2\n",
       "1     156062          2\n",
       "2     156063          2\n",
       "3     156064          2\n",
       "4     156065          2\n",
       "5     156066          2\n",
       "6     156067          2\n",
       "7     156068          2\n",
       "8     156069          2\n",
       "9     156070          2\n",
       "10    156071          2\n",
       "11    156072          2\n",
       "12    156073          2\n",
       "13    156074          2\n",
       "14    156075          2\n",
       "15    156076          2\n",
       "16    156077          2\n",
       "17    156078          2\n",
       "18    156079          2\n",
       "19    156080          2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the submission frame that we have to submit\n",
    "submission = pd.DataFrame(list(zip(test_id, y_prdict)),\n",
    "               columns =['PhraseId', 'Sentiment'])\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the frame\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
